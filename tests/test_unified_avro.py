#!/usr/bin/env python3
"""
í†µí•© Avro Producer í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

KafkaProducerClient ê¸°ë³¸ í´ë˜ìŠ¤ì˜ Avro ì§ë ¬í™” ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
"""

import asyncio

import pytest

from src.common.logger import PipelineLogger
from src.infra.messaging.connect.producers.control.connect_success import (
    ConnectSuccessEventProducer,
)
from src.infra.messaging.connect.producers.metrics.metrics import MetricsProducer
from src.infra.messaging.connect.producers.realtime.realtime_data import (
    RealtimeDataProducer,
)
from tests.factory_builders import build_scope_domain, build_ticker_batch_payload

logger = PipelineLogger.get_logger("unified_avro_test", "main")

pytestmark = pytest.mark.skip(
    reason="Integration smoke script requires external Kafka/Schema Registry"
)


async def test_ticker_producer():
    """í‹°ì»¤ Producer Avro í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ¯ í‹°ì»¤ Producer Avro í…ŒìŠ¤íŠ¸ ì‹œì‘")

    # Avro í™œì„±í™”ëœ Producer
    producer = RealtimeDataProducer(use_avro=True)

    # Avro ìƒíƒœ í™•ì¸
    status = producer.get_avro_status()
    logger.info(f"Avro ìƒíƒœ: {status}")

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_batch = build_ticker_batch_payload()

    scope = build_scope_domain(exchange="binance", region="asia")

    try:
        success = await producer.send_ticker_batch(scope, test_batch)
        if success:
            logger.info("âœ… í‹°ì»¤ ë°°ì¹˜ ì „ì†¡ ì„±ê³µ!")
        else:
            logger.error("âŒ í‹°ì»¤ ë°°ì¹˜ ì „ì†¡ ì‹¤íŒ¨!")
    except Exception as e:
        logger.error(f"í‹°ì»¤ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")


async def test_metrics_producer():
    """ë©”íŠ¸ë¦­ Producer Avro í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ“Š ë©”íŠ¸ë¦­ Producer Avro í…ŒìŠ¤íŠ¸ ì‹œì‘")

    # Avro í™œì„±í™”ëœ Producer (ê¸°ë³¸ê°’)
    producer = MetricsProducer(use_avro=True)

    # Avro ìƒíƒœ í™•ì¸
    status = producer.get_avro_status()
    logger.info(f"ë©”íŠ¸ë¦­ Avro ìƒíƒœ: {status}")

    # JSON ë°©ì‹ìœ¼ë¡œë„ ì‚¬ìš© ê°€ëŠ¥
    json_producer = MetricsProducer(use_avro=False)
    json_status = json_producer.get_avro_status()
    logger.info(f"ë©”íŠ¸ë¦­ JSON ìƒíƒœ: {json_status}")


async def test_connect_success_producer():
    """ì—°ê²° ì„±ê³µ Producer Avro í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ”— ì—°ê²° ì„±ê³µ Producer Avro í…ŒìŠ¤íŠ¸ ì‹œì‘")

    # Avro í™œì„±í™”ëœ Producer
    producer = ConnectSuccessEventProducer(use_avro=True)

    # Avro ìƒíƒœ í™•ì¸
    status = producer.get_avro_status()
    logger.info(f"ì—°ê²° ì„±ê³µ Avro ìƒíƒœ: {status}")


async def test_avro_toggle():
    """Avro í™œì„±í™”/ë¹„í™œì„±í™” í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ”„ Avro í† ê¸€ í…ŒìŠ¤íŠ¸ ì‹œì‘")

    # JSON ë°©ì‹ìœ¼ë¡œ ì‹œì‘
    producer = RealtimeDataProducer(use_avro=False)

    # ì´ˆê¸° ìƒíƒœ
    logger.info(f"ì´ˆê¸° ìƒíƒœ (JSON): {producer.get_avro_status()}")

    # Avro í™œì„±í™”
    producer.enable_avro("ticker-data-value")
    logger.info(f"Avro í™œì„±í™” í›„: {producer.get_avro_status()}")

    # Avro ë¹„í™œì„±í™”
    producer.disable_avro()
    logger.info(f"ë¹„í™œì„±í™” í›„: {producer.get_avro_status()}")


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("ğŸš€ í†µí•© Avro Producer í…ŒìŠ¤íŠ¸ ì‹œì‘")

    await test_ticker_producer()
    await test_metrics_producer()
    await test_connect_success_producer()
    await test_avro_toggle()

    logger.info("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(main())
